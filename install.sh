#!/bin/bash

# Vision LLM Video QA Installation Script

echo "ðŸš€ Installing Vision LLM Video QA..."

# Check if Python 3.8+ is installed
python_version=$(python3 -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
required_version="3.8"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" = "$required_version" ]; then
    echo "âœ… Python $python_version detected (>= $required_version)"
else
    echo "âŒ Python 3.8+ is required. Current version: $python_version"
    exit 1
fi

# Create virtual environment
echo "ðŸ“¦ Creating virtual environment..."
python3 -m venv venv
source venv/bin/activate

# Upgrade pip
echo "â¬†ï¸  Upgrading pip..."
pip install --upgrade pip

# Install Python dependencies
echo "ðŸ“š Installing Python dependencies..."
pip install -r requirements.txt

# Check if Ollama is installed
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
else
    echo "ðŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# Pull required Ollama model
echo "ðŸ¤– Pulling Gemma 2B model..."
ollama pull gemma:2b

echo ""
echo "ðŸŽ‰ Installation complete!"
echo ""
echo "ðŸ“‹ Next steps:"
echo "1. Activate the virtual environment: source venv/bin/activate"
echo "2. Start Ollama: ollama serve"
echo "3. Run the example: python example.py"
echo ""
echo "ðŸ“– For more information, see README.md"
